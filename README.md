# An-Approach-to-Resolving-Persona-Knowledge-Gap-in-Multi-Turn-Conversations-Using-LLMs

<img src="images/stages 2.png" alt="CPER Framework" style="width:60%; height:auto;">

**CPER** (Conversation Preference Elicitation and Recommendation) is a framework designed to address the persona knowledge gap in multi-turn conversations. The system dynamically extracts user-specific information, estimates uncertainty, and refines responses by asking clarifying questions. This results in more coherent, personalized, and context-aware interactions with large language models (LLMs).

## Features

- **Persona-Aware Dialogue Management**:  
  üìå Dynamic persona extraction and tracking  
  üìä Knowledge gap quantification (WCMI + Uncertainty scoring)  
  üîÑ Iterative response refinement with self-feedback  

- **Multi-Dataset Support**:  
  üé• **CCPE-M**: Movie preference tracking dataset  
  üí¨ **ESConv**: Emotional support conversation dataset  

- **Advanced Metrics**:  
  ü§ñ GPT-4 preference scoring  
  üß† NUBIA semantic consistency evaluation  

  # CPER: From Guessing to Asking

## Table of Contents

- [Overview](#overview)
- [Folder Structure](#folder-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Dataset Format](#dataset-format)
- [Algorithm Overview](#algorithm-overview)

## Overview

In multi-turn dialogues, LLMs often struggle to maintain a consistent understanding of user-specific context‚Äîwhat we call the **persona knowledge gap**. The **CPER** framework overcomes this by:
  
1. **Extracting Persona Information:**  
   Generating multiple candidate persona extractions from a user‚Äôs input.

2. **Estimating Uncertainty:**  
   Computing uncertainty over the candidate extractions using cosine dissimilarity of embeddings.

3. **Feedback & Persona Selection:**  
   Generating feedback to identify missing or inconsistent context and selecting the best persona representation.

4. **Refined Response Generation:**  
   Producing a final, context-aware response using all available information.

## Folder Structure
- **prompts/**  
  Contains the prompt templates used to guide the LLM for persona extraction, feedback generation, persona retrieval, and response refinement.

- **arg_parser.py**  
  Parses command-line inputs such as the dataset path, temperature, and max tokens.

- **cper_framework.py**  
  Implements the CPER framework with functions to process each conversation turn, including generating multiple candidate persona extractions and computing the associated uncertainty.

- **utils.py**  
  Contains utility functions for querying the LLM, generating embeddings, calculating cosine similarities, embedding variance, attention similarity, and the persona knowledge gap.

- **main.py**  
  Integrates everything by reading the dataset, iterating over conversation turns, and processing each turn with the CPER framework.

## Dataset format
### CCPE-M Example
[
  {
    "conversation_id": "CCPE-8e113",
    "turns": [
      {
        "user_input": "I like thrillers a lot.",
        "response": "thrillers? for example?"
      },
      {
        "user_input": "Zodiac's one of my favorite movies. Zodiac the movie about a serial killer from the '60s or '70s, around there.",
        "response": "Zodiac? oh wow ok, what do you like about that movie"
      }
    ]
  }
]

### ESConv Example
[
  {
    "conversation_id": "anxiety_job_crisis",
    "emotion_type": "anxiety",
    "problem_type": "job crisis",
    "situation": "I hate my job but I am scared to quit and seek a new career.",
    "turns": [
      {
        "user_input": "Hello",
        "response": "Hello, what would you like to talk about?"
      },
      {
        "user_input": "I am having a lot of anxiety about quitting my current job. It is too stressful but pays well",
        "response": "What makes your job stressful for you?"
      }
    ]
  }
]

## Algorithm Overview
Below is the CPER algorithm that describes how CPER generates multiple candidate responses and selects one candidate for subsequent processing:
Algorithm: CPER Algorithm

Input: 
- Dialogue {x‚ÇÅ, x‚ÇÇ, ..., x‚Çú}
- Model {M}
- Prompts {p_gen, p_fb, p_select, p_refine}
- Constants {Œ±, Œ≤}

Initialize:
P_history = ‚àÖ

For each utterance x‚Çú in {x‚ÇÅ, x‚ÇÇ, ..., x‚Çú}:
    1. {y‚ÇÄ‚Å±, p‚Çú‚Å±}·µ¢‚Çå‚ÇÅ‚Åµ = {M(p_gen || x‚Çú)}·µ¢‚Çå‚ÇÅ‚Åµ
    2. P_history = P_history ‚à™ p‚Çú¬π
    3. Uncertainty(p‚Çú) = Eq.(uncertainty)
    4. WCMI(p‚Çú, P_history) = Eq.(wcmi)
    5. KG‚Çú = Eq.(knowledge_gap)
    6. f‚Çú = M(p_fb || x‚Çú || y‚ÇÄ || KG‚Çú)
    7. P_selected = M(p_select || x‚Çú || P_history || f‚Çú)
    8. y‚Çú = M(p_refine || x‚Çú || y‚ÇÄ || f‚Çú || P_selected)

Return: {y‚ÇÅ, y‚ÇÇ, ..., y‚Çú}




